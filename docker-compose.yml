services:
  # SERVICE 1: THE BRAIN (Backend)
  rag_app:
    build: .
    container_name: agy_rag_backend
    ports:
      - "5050:5050"
    env_file:
      - .env
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - HF_HOME=/app/data/.huggingface
      - L1_URL=http://ollama:11434
    volumes:
      - .:/app
      - ./data/huggingface:/app/data/.huggingface
    depends_on:
      - chroma_db
      - postgres_db
      - ollama
    shm_size: '8gb'
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]
    restart: "no"

  # SERVICE 2: THE MEMORY (Vector Store)
  chroma_db:
    image: chromadb/chroma:latest
    container_name: agy_chroma
    volumes:
      - ./data/chroma_data:/chroma/chroma
    environment:
      - IS_PERSISTENT=TRUE
    ports:
      - "8000:8000"
    networks:
      default:

        # SERVICE 3: THE AMNESIA FIX (Chat History)
  postgres_db:
    image: postgres:16-alpine
    container_name: agy_postgres
    restart: always
    environment:
      - POSTGRES_USER=${DB_USER:-agy_user}
      - POSTGRES_PASSWORD=${DB_PASSWORD:-agy_pass}
      - POSTGRES_DB=${DB_NAME:-chat_history}
    ports:
      - "5432:5432"
    volumes:
      - ./data/postgres_data:/var/lib/postgresql/data
    networks:
      default:

        # SERVICE 4: THE BRAIN (Local Inference - Generation)
  ollama:
    image: ollama/ollama:latest
    container_name: agy_ollama
    environment:
      - CUDA_VISIBLE_DEVICES=0
    volumes:
      - ./data/ollama_models:/root/.ollama
    ports:
      - "11434:11434"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: [ '0' ]
              capabilities: [ gpu ]
    networks:
      default:

        # SERVICE 5: THE EMBEDDER (GPU 1 - 6GB GTX 1060)
  ollama_embed:
    image: ollama/ollama:latest
    container_name: agy_ollama_embed
    environment:
      - CUDA_VISIBLE_DEVICES=1
    volumes:
      - ./data/ollama_embed_models:/root/.ollama
    ports:
      - "11435:11434"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: [ '1' ]
              capabilities: [ gpu ]
    networks:
      default:

        # SERVICE 6: QDRANT (Hybrid Vector DB)
  qdrant:
    image: qdrant/qdrant:latest
    container_name: agy_qdrant
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - ./data/qdrant:/qdrant/storage
    environment:
      - QDRANT_ALLOW_RECOVERY_MODE=true
    networks:
      default:

        # SERVICE 7: MINIO (S3 Object Storage)
  minio:
    image: minio/minio:latest
    container_name: agy_minio
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - ./data/minio:/data
    environment:
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minioadmin
    command: server /data --console-address ":9001"
    networks:
      default:
